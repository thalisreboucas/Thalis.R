---
title: Regressão linear
author: 'Thalis Rebouças'
date: '2023-01-23'
slug: regress-o-linear
categories: R
tags: 
- R
- Machine Learning
description: AL.EM
image: images/portfolio/rgl.png
draft: no
---



<div id="regressão-linear" class="section level2">
<h2>Regressão Linear</h2>
<div id="o-que-é-isso" class="section level3">
<h3>O que é isso ?</h3>
<p>A regressão é de maneira geral no caso simples é uma formula que você consegue gerar uma reta e essa reta descreve o comportamento de uma relação linear nos parâmetros e assim , conseguir entender o <span class="math inline">\(\alpha\)</span> e o <span class="math inline">\(\beta\)</span> que gera a reta assim conseguindo prever os possiveis valores ou <em>(depende de normalidade essa parte)</em> fazer inferência de <code>segunda ordem</code>.
Já na multipla não temos mais uma reta e sim um <em>Hiperplano</em> ,pronto finalizamos o resumo conceito, bora para as formulas :</p>
</div>
<div id="importante-para-fazer-regressão" class="section level3">
<h3>Importante para fazer Regressão :</h3>
<div id="linear-simples" class="section level4">
<h4>Linear Simples :</h4>
<p>A coisa mais importante para fazer regressão são seus presupostos neste caso são cinco :</p>
<ol style="list-style-type: decimal">
<li>A função de Regressão é Linear nos parâmtros.(<span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>)</li>
<li>Os valores dos <span class="math inline">\(x_i\)</span> são fixos e conhecidos ,não são uma variável aleatória.</li>
<li>Os erros tem média 0, ou seja, <span class="math inline">\(E[e_i|x_i] = 0\)</span></li>
<li>Os erros tem varância 1 e constante (Homoscesdaticidade), ou seja, <span class="math inline">\(Var[e_i|x_i] = \sigma^2\)</span></li>
<li>Os erros são não correlacionados, <span class="math inline">\(Cov(e_i,e_j) = E[e_ie_j]=0\)</span></li>
</ol>
<p>A formula é dado por :</p>
<p><span class="math display">\[y_i = \alpha + \beta x_i + e_i\ \ i =1,...,n
\]</span></p>
</div>
<div id="linear-multipla" class="section level4">
<h4>Linear Multipla :</h4>
<ol style="list-style-type: decimal">
<li>A função de Regressão é Linear nos parâmtros.(<span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta_n\)</span>)</li>
<li>Os valores dos <span class="math inline">\(x_i\)</span> são fixos e conhecidos, a matriz de especificação $X(n  p) $ sendo não aleatória e de posto completo.</li>
<li>Os erros tem média 0, ou seja, <span class="math inline">\(E[e_i|x_i] = 0\)</span></li>
<li>Os erros tem varância 1 e constante (Homoscesdaticidade), ou seja, <span class="math inline">\(Var[e_i|x_i] = \sigma^2I_n\)</span></li>
<li>Os erros são não correlacionados, <span class="math inline">\(Cov(e_i,e_j) = E[e_ie_j]=0\)</span></li>
</ol>
<p><span class="math display">\[y_i = \alpha + \beta_1 x_{1i} +\beta_2 x_{2i} + e_i\ \ i =1,...,n
\]</span></p>
</div>
<div id="métodos-dos-mínimos-quadrados" class="section level4">
<h4>Métodos dos Mínimos Quadrados:</h4>
<p>Esse é o método padrão que o software R usa e com isso ele estima a melhor retá que minimiza a distância do valor observado para o valor ajustado da reta.</p>
</div>
<div id="estimação-dos-parâmentros" class="section level4">
<h4>Estimação dos Parâmentros:</h4>
<p>Neste caso o <span class="math inline">\(\alpha\)</span> estimado da reta é dada pela seguinte formula :</p>
<p><span class="math display">\[\alpha = \bar{y}-\beta \bar{x}
\]</span></p>
<p>Onde o <span class="math inline">\(\bar{y}\)</span> é a média amostral de <span class="math inline">\(Y\)</span> ,que é a variável resposta e <span class="math inline">\(\bar{x}\)</span> é a média dos <span class="math inline">\(x_i\)</span>,que são as variáveis explicativas.</p>
<p>Agora para estimar o <span class="math inline">\(\beta\)</span> temos a seguinte formula :</p>
<p><span class="math display">\[\beta = \dfrac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2} = \dfrac{Sxy}{Sxx}
\]</span></p>
<p>Na forma matricial o <span class="math inline">\(\beta\)</span> é dado pela seguinte formula :</p>
<p><span class="math display">\[\beta = (X^TX)^{-1}X^Ty
\]</span></p>
<p>Todas as provas deste metodo é disponibilizado neste site <a href="https://statproofbook.github.io/I/ToC">statproofbook</a> na seção 1.4 e na seçãp 1.5 tem a provas em matrizes na forma multipla.O Teorema Gauss-Markov garante (embora indiretamente) que o estimador de mínimos quadrados é o estimador não-enviesado de mínima variância linear na variável resposta,caso siga uma distribuição normal.</p>
</div>
<div id="formula-exata-dos-parâmetros" class="section level4">
<h4>Formula exata dos Parâmetros:</h4>
<p>Uma das coisas importantes da estatística é saber a sua média e também a sua variânça,por isso, temos que :</p>
<ol style="list-style-type: decimal">
<li><p>Variância do <span class="math inline">\(\alpha\)</span> :
<span class="math display">\[Var[\hat{\alpha}] =\sigma^2(\frac{1}{n}+\frac{\bar{x}_n^2}{Sxx})
\]</span></p></li>
<li><p>Variância do <span class="math inline">\(\beta\)</span> :
<span class="math display">\[Var[\hat{\beta}] = \dfrac{\sigma^2}{Sxx}
\]</span></p></li>
<li><p>Covariância
<span class="math display">\[Cov(\hat{\alpha},\hat{\beta})= -\dfrac{\sigma^2\hat{x}_n}{Sxx}\]</span></p></li>
</ol>
<p>Os valores das variâncias são quantidades pivotais, ou seja, caso siga normalidade,podemos fazer intervalo de confiança e teste de hiposteses.</p>
<p>teste modo temos que a formula exata,seguindo normalidade, é dada por :</p>
<p><span class="math display">\[\hat{\alpha} \sim N(\alpha,\sigma^2(\frac{1}{n}+\frac{\bar{x}_n^2}{Sxx}))
\]</span>
<span class="math display">\[\hat{\beta} \sim N(\beta,\dfrac{\sigma^2}{Sxx})
\]</span></p>
</div>
<div id="resíduos-e-o-r-quadratico" class="section level4">
<h4>Resíduos e o R-quadratico :</h4>
</div>
<div id="anova" class="section level4">
<h4>ANOVA:</h4>
</div>
<div id="intervalo-de-confiaça-e-intervalo-de-predição" class="section level4">
<h4>Intervalo de Confiaça e Intervalo de Predição :</h4>
</div>
</div>
<div id="regressão-no-r" class="section level3">
<h3>Regressão no R :</h3>
<p>Para fazer Regressão no R vamos precisar dos seguintes pacotes o <code>easystats</code> ,<code>tidyverse</code>,<code>tidymodels</code> e <code>plotly</code>. A regressão é feita pelo comando <em>lm(y~x)</em> e no caso multiplo é só somar mais um variavel explicativa <em>lm(y ~ x1+ x2)</em>.</p>
<p>Vamos pegar uma base como exemplo,usando a função <code>report()</code> do easystats para descrever a base de dados <a href="https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars">mtcars</a></p>
<pre class="r"><code># Pacote para abrir pacotes,atualizar e instalar os que não tem.
library(pacman)
#  chamando os pacotes
pacman::p_load(easystats,tidyverse,tidymodels,tidygraph,plotly)

# base de dados mtcars

# Fazendo uma tabela com as principais medidas de posição e disperção.
report_table(mtcars) %&gt;% knitr::kable(digits = 3)</code></pre>
<table style="width:100%;">
<colgroup>
<col width="3%" />
<col width="9%" />
<col width="6%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="7%" />
<col width="8%" />
<col width="9%" />
<col width="9%" />
<col width="10%" />
</colgroup>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Variable</th>
<th align="right">n_Obs</th>
<th align="right">Mean</th>
<th align="right">SD</th>
<th align="right">Median</th>
<th align="right">MAD</th>
<th align="right">Min</th>
<th align="right">Max</th>
<th align="right">Skewness</th>
<th align="right">Kurtosis</th>
<th align="right">n_Missing</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">9</td>
<td align="left">mpg</td>
<td align="right">32</td>
<td align="right">20.091</td>
<td align="right">6.027</td>
<td align="right">19.200</td>
<td align="right">5.411</td>
<td align="right">10.400</td>
<td align="right">33.900</td>
<td align="right">0.672</td>
<td align="right">-0.022</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">7</td>
<td align="left">cyl</td>
<td align="right">32</td>
<td align="right">6.188</td>
<td align="right">1.786</td>
<td align="right">6.000</td>
<td align="right">2.965</td>
<td align="right">4.000</td>
<td align="right">8.000</td>
<td align="right">-0.192</td>
<td align="right">-1.763</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">11</td>
<td align="left">disp</td>
<td align="right">32</td>
<td align="right">230.722</td>
<td align="right">123.939</td>
<td align="right">196.300</td>
<td align="right">140.476</td>
<td align="right">71.100</td>
<td align="right">472.000</td>
<td align="right">0.420</td>
<td align="right">-1.068</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="left">hp</td>
<td align="right">32</td>
<td align="right">146.688</td>
<td align="right">68.563</td>
<td align="right">123.000</td>
<td align="right">77.095</td>
<td align="right">52.000</td>
<td align="right">335.000</td>
<td align="right">0.799</td>
<td align="right">0.275</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="left">drat</td>
<td align="right">32</td>
<td align="right">3.597</td>
<td align="right">0.535</td>
<td align="right">3.695</td>
<td align="right">0.704</td>
<td align="right">2.760</td>
<td align="right">4.930</td>
<td align="right">0.293</td>
<td align="right">-0.450</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="left">wt</td>
<td align="right">32</td>
<td align="right">3.217</td>
<td align="right">0.978</td>
<td align="right">3.325</td>
<td align="right">0.767</td>
<td align="right">1.513</td>
<td align="right">5.424</td>
<td align="right">0.466</td>
<td align="right">0.417</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">8</td>
<td align="left">qsec</td>
<td align="right">32</td>
<td align="right">17.849</td>
<td align="right">1.787</td>
<td align="right">17.710</td>
<td align="right">1.416</td>
<td align="right">14.500</td>
<td align="right">22.900</td>
<td align="right">0.406</td>
<td align="right">0.865</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="left">vs</td>
<td align="right">32</td>
<td align="right">0.438</td>
<td align="right">0.504</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">1.000</td>
<td align="right">0.265</td>
<td align="right">-2.063</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">1</td>
<td align="left">am</td>
<td align="right">32</td>
<td align="right">0.406</td>
<td align="right">0.499</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">0.000</td>
<td align="right">1.000</td>
<td align="right">0.401</td>
<td align="right">-1.967</td>
<td align="right">0</td>
</tr>
<tr class="even">
<td align="left">6</td>
<td align="left">gear</td>
<td align="right">32</td>
<td align="right">3.688</td>
<td align="right">0.738</td>
<td align="right">4.000</td>
<td align="right">1.483</td>
<td align="right">3.000</td>
<td align="right">5.000</td>
<td align="right">0.582</td>
<td align="right">-0.895</td>
<td align="right">0</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="left">carb</td>
<td align="right">32</td>
<td align="right">2.812</td>
<td align="right">1.615</td>
<td align="right">2.000</td>
<td align="right">1.483</td>
<td align="right">1.000</td>
<td align="right">8.000</td>
<td align="right">1.157</td>
<td align="right">2.020</td>
<td align="right">0</td>
</tr>
</tbody>
</table>
<pre class="r"><code># Vendo as correlações
plot(correlation(mtcars, partial = TRUE)) +
  scale_edge_color_continuous(low = &quot;#000000&quot;, high = &quot;#f55b14&quot;) </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code>correlation(mtcars)  </code></pre>
<pre><code>## # Correlation Matrix (pearson-method)
## 
## Parameter1 | Parameter2 |     r |         95% CI | t(30) |         p
## --------------------------------------------------------------------
## mpg        |        cyl | -0.85 | [-0.93, -0.72] | -8.92 | &lt; .001***
## mpg        |       disp | -0.85 | [-0.92, -0.71] | -8.75 | &lt; .001***
## mpg        |         hp | -0.78 | [-0.89, -0.59] | -6.74 | &lt; .001***
## mpg        |       drat |  0.68 | [ 0.44,  0.83] |  5.10 | &lt; .001***
## mpg        |         wt | -0.87 | [-0.93, -0.74] | -9.56 | &lt; .001***
## mpg        |       qsec |  0.42 | [ 0.08,  0.67] |  2.53 | 0.222    
## mpg        |         vs |  0.66 | [ 0.41,  0.82] |  4.86 | 0.001**  
## mpg        |         am |  0.60 | [ 0.32,  0.78] |  4.11 | 0.008**  
## mpg        |       gear |  0.48 | [ 0.16,  0.71] |  3.00 | 0.097    
## mpg        |       carb | -0.55 | [-0.75, -0.25] | -3.62 | 0.024*   
## cyl        |       disp |  0.90 | [ 0.81,  0.95] | 11.45 | &lt; .001***
## cyl        |         hp |  0.83 | [ 0.68,  0.92] |  8.23 | &lt; .001***
## cyl        |       drat | -0.70 | [-0.84, -0.46] | -5.37 | &lt; .001***
## cyl        |         wt |  0.78 | [ 0.60,  0.89] |  6.88 | &lt; .001***
## cyl        |       qsec | -0.59 | [-0.78, -0.31] | -4.02 | 0.010*   
## cyl        |         vs | -0.81 | [-0.90, -0.64] | -7.59 | &lt; .001***
## cyl        |         am | -0.52 | [-0.74, -0.21] | -3.36 | 0.043*   
## cyl        |       gear | -0.49 | [-0.72, -0.17] | -3.10 | 0.079    
## cyl        |       carb |  0.53 | [ 0.22,  0.74] |  3.40 | 0.041*   
## disp       |         hp |  0.79 | [ 0.61,  0.89] |  7.08 | &lt; .001***
## disp       |       drat | -0.71 | [-0.85, -0.48] | -5.53 | &lt; .001***
## disp       |         wt |  0.89 | [ 0.78,  0.94] | 10.58 | &lt; .001***
## disp       |       qsec | -0.43 | [-0.68, -0.10] | -2.64 | 0.197    
## disp       |         vs | -0.71 | [-0.85, -0.48] | -5.53 | &lt; .001***
## disp       |         am | -0.59 | [-0.78, -0.31] | -4.02 | 0.010*   
## disp       |       gear | -0.56 | [-0.76, -0.26] | -3.66 | 0.023*   
## disp       |       carb |  0.39 | [ 0.05,  0.65] |  2.35 | 0.303    
## hp         |       drat | -0.45 | [-0.69, -0.12] | -2.75 | 0.170    
## hp         |         wt |  0.66 | [ 0.40,  0.82] |  4.80 | 0.001**  
## hp         |       qsec | -0.71 | [-0.85, -0.48] | -5.49 | &lt; .001***
## hp         |         vs | -0.72 | [-0.86, -0.50] | -5.73 | &lt; .001***
## hp         |         am | -0.24 | [-0.55,  0.12] | -1.37 | &gt; .999   
## hp         |       gear | -0.13 | [-0.45,  0.23] | -0.69 | &gt; .999   
## hp         |       carb |  0.75 | [ 0.54,  0.87] |  6.21 | &lt; .001***
## drat       |         wt | -0.71 | [-0.85, -0.48] | -5.56 | &lt; .001***
## drat       |       qsec |  0.09 | [-0.27,  0.43] |  0.50 | &gt; .999   
## drat       |         vs |  0.44 | [ 0.11,  0.68] |  2.69 | 0.187    
## drat       |         am |  0.71 | [ 0.48,  0.85] |  5.57 | &lt; .001***
## drat       |       gear |  0.70 | [ 0.46,  0.84] |  5.36 | &lt; .001***
## drat       |       carb | -0.09 | [-0.43,  0.27] | -0.50 | &gt; .999   
## wt         |       qsec | -0.17 | [-0.49,  0.19] | -0.97 | &gt; .999   
## wt         |         vs | -0.55 | [-0.76, -0.26] | -3.65 | 0.023*   
## wt         |         am | -0.69 | [-0.84, -0.45] | -5.26 | &lt; .001***
## wt         |       gear | -0.58 | [-0.77, -0.29] | -3.93 | 0.012*   
## wt         |       carb |  0.43 | [ 0.09,  0.68] |  2.59 | 0.205    
## qsec       |         vs |  0.74 | [ 0.53,  0.87] |  6.11 | &lt; .001***
## qsec       |         am | -0.23 | [-0.54,  0.13] | -1.29 | &gt; .999   
## qsec       |       gear | -0.21 | [-0.52,  0.15] | -1.19 | &gt; .999   
## qsec       |       carb | -0.66 | [-0.82, -0.40] | -4.76 | 0.001**  
## vs         |         am |  0.17 | [-0.19,  0.49] |  0.94 | &gt; .999   
## vs         |       gear |  0.21 | [-0.15,  0.52] |  1.15 | &gt; .999   
## vs         |       carb | -0.57 | [-0.77, -0.28] | -3.80 | 0.017*   
## am         |       gear |  0.79 | [ 0.62,  0.89] |  7.16 | &lt; .001***
## am         |       carb |  0.06 | [-0.30,  0.40] |  0.32 | &gt; .999   
## gear       |       carb |  0.27 | [-0.08,  0.57] |  1.56 | &gt; .999   
## 
## p-value adjustment method: Holm (1979)
## Observations: 32</code></pre>
</div>
</div>
