---
title: Regressão linear
author: 'Thalis Rebouças'
date: '2023-01-23'
slug: regress-o-linear
categories: R
tags: 
- R
- Machine Learning
description: AL.EM
image: images/portfolio/rgl.png
draft: no
---

<script src="{{< blogdown/postref >}}index_files/kePrint/kePrint.js"></script>
<link href="{{< blogdown/postref >}}index_files/lightable/lightable.css" rel="stylesheet" />


<div id="regressão-linear" class="section level2">
<h2>Regressão Linear</h2>
<div id="o-que-é-isso" class="section level3">
<h3>O que é isso ?</h3>
<p>A regressão é de maneira geral no caso simples é uma formula que você consegue gerar uma reta e essa reta descreve o comportamento de uma relação linear nos parâmetros e assim , conseguir entender o <span class="math inline">\(\alpha\)</span> e o <span class="math inline">\(\beta\)</span> que gera a reta assim conseguindo prever os possiveis valores ou <em>(depende de normalidade essa parte)</em> fazer inferência de <code>segunda ordem</code>.
Já na multipla não temos mais uma reta e sim um <em>Hiperplano</em> ,pronto finalizamos o resumo conceito, bora para as formulas :</p>
</div>
<div id="importante-para-fazer-regressão" class="section level3">
<h3>Importante para fazer Regressão :</h3>
<div id="linear-simples" class="section level4">
<h4>Linear Simples :</h4>
<p>A coisa mais importante para fazer regressão são seus presupostos neste caso são cinco :</p>
<ol style="list-style-type: decimal">
<li>A função de Regressão é Linear nos parâmtros.(<span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta\)</span>)</li>
<li>Os valores dos <span class="math inline">\(x_i\)</span> são fixos e conhecidos ,não são uma variável aleatória.</li>
<li>Os erros tem média 0, ou seja, <span class="math inline">\(E[e_i|x_i] = 0\)</span></li>
<li>Os erros tem varância 1 e constante (Homoscesdaticidade), ou seja, <span class="math inline">\(Var[e_i|x_i] = \sigma^2\)</span></li>
<li>Os erros são não correlacionados, <span class="math inline">\(Cov(e_i,e_j) = E[e_ie_j]=0\)</span></li>
</ol>
<p>A formula é dado por :</p>
<p><span class="math display">\[y_i = \alpha + \beta x_i + e_i\ \ i =1,...,n
\]</span></p>
</div>
<div id="linear-multipla" class="section level4">
<h4>Linear Multipla :</h4>
<ol style="list-style-type: decimal">
<li>A função de Regressão é Linear nos parâmtros.(<span class="math inline">\(\alpha\)</span> e <span class="math inline">\(\beta_n\)</span>)</li>
<li>Os valores dos <span class="math inline">\(x_i\)</span> são fixos e conhecidos, a matriz de especificação $X(n  p) $ sendo não aleatória e de posto completo.</li>
<li>Os erros tem média 0, ou seja, <span class="math inline">\(E[e_i|x_i] = 0\)</span></li>
<li>Os erros tem varância 1 e constante (Homoscesdaticidade), ou seja, <span class="math inline">\(Var[e_i|x_i] = \sigma^2I_n\)</span></li>
<li>Os erros são não correlacionados, <span class="math inline">\(Cov(e_i,e_j) = E[e_ie_j]=0\)</span></li>
</ol>
<p><span class="math display">\[y_i = \alpha + \beta_1 x_{1i} +\beta_2 x_{2i} + e_i\ \ i =1,...,n
\]</span></p>
</div>
<div id="métodos-dos-mínimos-quadrados" class="section level4">
<h4>Métodos dos Mínimos Quadrados:</h4>
<p>Esse é o método padrão que o software R usa e com isso ele estima a melhor retá que minimiza a distância do valor observado para o valor ajustado da reta.</p>
</div>
<div id="estimação-dos-parâmentros" class="section level4">
<h4>Estimação dos Parâmentros:</h4>
<p>Neste caso o <span class="math inline">\(\alpha\)</span> estimado da reta é dada pela seguinte formula :</p>
<p><span class="math display">\[\alpha = \bar{y}-\beta \bar{x}
\]</span></p>
<p>Onde o <span class="math inline">\(\bar{y}\)</span> é a média amostral de <span class="math inline">\(Y\)</span> ,que é a variável resposta e <span class="math inline">\(\bar{x}\)</span> é a média dos <span class="math inline">\(x_i\)</span>,que são as variáveis explicativas.</p>
<p>Agora para estimar o <span class="math inline">\(\beta\)</span> temos a seguinte formula :</p>
<p><span class="math display">\[\beta = \dfrac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2} = \dfrac{Sxy}{Sxx}
\]</span></p>
<p>Na forma matricial o <span class="math inline">\(\beta\)</span> é dado pela seguinte formula :</p>
<p><span class="math display">\[\beta = (X^TX)^{-1}X^Ty
\]</span></p>
<p>Todas as provas deste metodo é disponibilizado neste site <a href="https://statproofbook.github.io/I/ToC">statproofbook</a> na seção 1.4 e na seçãp 1.5 tem a provas em matrizes na forma multipla.O Teorema Gauss-Markov garante (embora indiretamente) que o estimador de mínimos quadrados é o estimador não-enviesado de mínima variância linear na variável resposta,caso siga uma distribuição normal.</p>
</div>
<div id="formula-exata-dos-parâmetros" class="section level4">
<h4>Formula exata dos Parâmetros:</h4>
<p>Uma das coisas importantes da estatística é saber a sua média e também a sua variânça,por isso, temos que :</p>
<ol style="list-style-type: decimal">
<li><p>Variância do <span class="math inline">\(\alpha\)</span> :
<span class="math display">\[Var[\hat{\alpha}] =\sigma^2(\frac{1}{n}+\frac{\bar{x}_n^2}{Sxx})
\]</span></p></li>
<li><p>Variância do <span class="math inline">\(\beta\)</span> :
<span class="math display">\[Var[\hat{\beta}] = \dfrac{\sigma^2}{Sxx}
\]</span></p></li>
<li><p>Covariância
<span class="math display">\[Cov(\hat{\alpha},\hat{\beta})= -\dfrac{\sigma^2\hat{x}_n}{Sxx}\]</span></p></li>
</ol>
<p>Os valores das variâncias são quantidades pivotais, ou seja, caso siga normalidade,podemos fazer intervalo de confiança e teste de hiposteses.</p>
<p>teste modo temos que a formula exata,seguindo normalidade, é dada por :</p>
<p><span class="math display">\[\hat{\alpha} \sim N(\alpha,\sigma^2(\frac{1}{n}+\frac{\bar{x}_n^2}{Sxx}))
\]</span>
<span class="math display">\[\hat{\beta} \sim N(\beta,\dfrac{\sigma^2}{Sxx})
\]</span></p>
</div>
<div id="resíduos" class="section level4">
<h4>Resíduos:</h4>
<p>Os resíduos são a diferença do valor observado menos o valor predito ,assim :</p>
<p><span class="math display">\[e_i = y_i-\hat{y_i}
\]</span></p>
<p>e temos que os resíduos segue um ruído branco :</p>
<p><span class="math display">\[e \sim RB(0,\sigma^2)
\]</span></p>
<p>O estimador para os resíduos é dado por :</p>
<p><span class="math display">\[\hat{e_i} = y_i - \hat{y_i} \sim (0 , 1 - \frac{1}{n}-\frac{(x_i-\bar{x_n})^2}{Sxx})
\]</span></p>
</div>
<div id="anova" class="section level4">
<h4>ANOVA:</h4>
<p>Temos a tabela da ANOVA, que possui os seguintes indicadores : Graus de Liberdade,Soma dos quadrados , Quadros médios e o Valor F(existência ou não de regressão)</p>
<p>Nela é possivel todos esses indicadores da Regressão,Resíduos e os totais .</p>
<table>
<colgroup>
<col width="15%" />
<col width="3%" />
<col width="29%" />
<col width="29%" />
<col width="22%" />
</colgroup>
<thead>
<tr class="header">
<th>Causa da Variação</th>
<th>GL</th>
<th>SQ</th>
<th>QM</th>
<th>F</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Regressão</td>
<td>1</td>
<td><span class="math inline">\(\sum_{i=1}^n(\hat{y}-\bar{y}_n)^2\)</span></td>
<td>Formula do lado dividido por 1</td>
<td>É a divisão do QMReg/QMRES</td>
</tr>
<tr class="even">
<td>Resíduos</td>
<td>n-2</td>
<td><span class="math inline">\(\sum_{i=1}^n(y-\hat{y}_n)^2\)</span></td>
<td>Formula do lado dividido por n - 2</td>
<td></td>
</tr>
<tr class="odd">
<td>Total</td>
<td>n-1</td>
<td><span class="math inline">\(\sum_{i=1}^n(y-\bar{y}_n)^2\)</span></td>
<td>Formula do lado dividido por n -1</td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div id="intervalo-de-confiança-e-intervalo-de-predição" class="section level4">
<h4>Intervalo de Confiança e Intervalo de Predição :</h4>
<p>Para fazer os Intervalo de Confiança ,eu preciso dos estimadores vistos a cima e os désvios padrões que vão ser a nossa quantidade pivotal.</p>
<p>Para fazer os Intervalo de Predição, eu preciso dos valores preditos e o désvio padrão do <span class="math inline">\(\alpha\)</span> que vai ser a nossa quantidade pivotal.</p>
</div>
</div>
<div id="regressão-no-r" class="section level3">
<h3>Regressão no R :</h3>
<p>Para fazer Regressão no R vamos precisar dos seguintes pacotes o <code>easystats</code> ,<code>tidyverse</code>,<code>tidymodels</code> e <code>plotly</code>. A regressão é feita pelo comando <em>lm(y~x)</em> e no caso multiplo é só somar mais um variavel explicativa <em>lm(y ~ x1+ x2)</em>.</p>
<p>Vamos pegar uma base como exemplo,usando a função <code>report()</code> do easystats para descrever a base de dados <a href="https://www.rdocumentation.org/packages/datasets/versions/3.6.2/topics/mtcars">mtcars</a></p>
<pre class="r"><code># Pacote para abrir pacotes,atualizar e instalar os que não tem.
library(pacman)
#  chamando os pacotes
pacman::p_load(easystats,tidyverse,tidymodels,tidygraph,plotly,car,kableExtra)

# base de dados mtcars

# Fazendo uma tabela com as principais medidas de posição e disperção.
report_table(mtcars) %&gt;% select(-n_Missing) %&gt;% kbl(digits = 2) %&gt;%
  kable_styling()</code></pre>
<table class="table" style="margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
n_Obs
</th>
<th style="text-align:right;">
Mean
</th>
<th style="text-align:right;">
SD
</th>
<th style="text-align:right;">
Median
</th>
<th style="text-align:right;">
MAD
</th>
<th style="text-align:right;">
Min
</th>
<th style="text-align:right;">
Max
</th>
<th style="text-align:right;">
Skewness
</th>
<th style="text-align:right;">
Kurtosis
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
9
</td>
<td style="text-align:left;">
mpg
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
20.09
</td>
<td style="text-align:right;">
6.03
</td>
<td style="text-align:right;">
19.20
</td>
<td style="text-align:right;">
5.41
</td>
<td style="text-align:right;">
10.40
</td>
<td style="text-align:right;">
33.90
</td>
<td style="text-align:right;">
0.67
</td>
<td style="text-align:right;">
-0.02
</td>
</tr>
<tr>
<td style="text-align:left;">
7
</td>
<td style="text-align:left;">
cyl
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
6.19
</td>
<td style="text-align:right;">
1.79
</td>
<td style="text-align:right;">
6.00
</td>
<td style="text-align:right;">
2.97
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
8.00
</td>
<td style="text-align:right;">
-0.19
</td>
<td style="text-align:right;">
-1.76
</td>
</tr>
<tr>
<td style="text-align:left;">
11
</td>
<td style="text-align:left;">
disp
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
230.72
</td>
<td style="text-align:right;">
123.94
</td>
<td style="text-align:right;">
196.30
</td>
<td style="text-align:right;">
140.48
</td>
<td style="text-align:right;">
71.10
</td>
<td style="text-align:right;">
472.00
</td>
<td style="text-align:right;">
0.42
</td>
<td style="text-align:right;">
-1.07
</td>
</tr>
<tr>
<td style="text-align:left;">
10
</td>
<td style="text-align:left;">
hp
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
146.69
</td>
<td style="text-align:right;">
68.56
</td>
<td style="text-align:right;">
123.00
</td>
<td style="text-align:right;">
77.10
</td>
<td style="text-align:right;">
52.00
</td>
<td style="text-align:right;">
335.00
</td>
<td style="text-align:right;">
0.80
</td>
<td style="text-align:right;">
0.28
</td>
</tr>
<tr>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
drat
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
3.60
</td>
<td style="text-align:right;">
0.53
</td>
<td style="text-align:right;">
3.70
</td>
<td style="text-align:right;">
0.70
</td>
<td style="text-align:right;">
2.76
</td>
<td style="text-align:right;">
4.93
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
-0.45
</td>
</tr>
<tr>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
wt
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
3.22
</td>
<td style="text-align:right;">
0.98
</td>
<td style="text-align:right;">
3.33
</td>
<td style="text-align:right;">
0.77
</td>
<td style="text-align:right;">
1.51
</td>
<td style="text-align:right;">
5.42
</td>
<td style="text-align:right;">
0.47
</td>
<td style="text-align:right;">
0.42
</td>
</tr>
<tr>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
qsec
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
17.85
</td>
<td style="text-align:right;">
1.79
</td>
<td style="text-align:right;">
17.71
</td>
<td style="text-align:right;">
1.42
</td>
<td style="text-align:right;">
14.50
</td>
<td style="text-align:right;">
22.90
</td>
<td style="text-align:right;">
0.41
</td>
<td style="text-align:right;">
0.86
</td>
</tr>
<tr>
<td style="text-align:left;">
2
</td>
<td style="text-align:left;">
vs
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.26
</td>
<td style="text-align:right;">
-2.06
</td>
</tr>
<tr>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
am
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
0.41
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
0.40
</td>
<td style="text-align:right;">
-1.97
</td>
</tr>
<tr>
<td style="text-align:left;">
6
</td>
<td style="text-align:left;">
gear
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
3.69
</td>
<td style="text-align:right;">
0.74
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
1.48
</td>
<td style="text-align:right;">
3.00
</td>
<td style="text-align:right;">
5.00
</td>
<td style="text-align:right;">
0.58
</td>
<td style="text-align:right;">
-0.90
</td>
</tr>
<tr>
<td style="text-align:left;">
3
</td>
<td style="text-align:left;">
carb
</td>
<td style="text-align:right;">
32
</td>
<td style="text-align:right;">
2.81
</td>
<td style="text-align:right;">
1.62
</td>
<td style="text-align:right;">
2.00
</td>
<td style="text-align:right;">
1.48
</td>
<td style="text-align:right;">
1.00
</td>
<td style="text-align:right;">
8.00
</td>
<td style="text-align:right;">
1.16
</td>
<td style="text-align:right;">
2.02
</td>
</tr>
</tbody>
</table>
<pre class="r"><code># Vendo as correlações
plot(correlation(mtcars))+
  scale_edge_color_continuous(low = &quot;#000000&quot;, high = &quot;#f55b14&quot;) </code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-2-1.png" width="768" /></p>
<pre><code># Tabela de correlação
t1 &lt;- correlation(mtcars) 

# transformando em um tablea apresentavel
t1 %&gt;%  
  dplyr::rename(&quot;p-value&quot; = &quot;p&quot;) %&gt;% 
  dplyr::select(-CI,-df_error,-Method,-n_Obs,-t)%&gt;% kbl(digits = 2) %&gt;%
  kable_styling()</code></pre>
<p>Vamor ver agora se o “mpg” = Milhas por galão (do inglês Miles/(US) gallon) é explicador pelo número de cilíndros “cyl” , potêcnia “hp” e peso “wt”.</p>
<p><span class="math display">\[Mpg = b_0 + x_1b_1 + x_2b_2 + x_3b_3
\]</span></p>
<p>Para aplicar a relação de minimos quadrados no r é usado o comando ´lm()´.</p>
<pre class="r"><code>modelo &lt;- lm( mpg ~ cyl + hp +wt ,data = mtcars )

# checando o modelo
model_performance(modelo)</code></pre>
<pre><code>## # Indices of model performance
## 
## AIC     |     BIC |    R2 | R2 (adj.) |  RMSE | Sigma
## -----------------------------------------------------
## 155.477 | 162.805 | 0.843 |     0.826 | 2.349 | 2.512</code></pre>
<p>Temos que esse modelo consegue explicar cerca de 82,6% a consumo de combustivel dos carros pelo número de cilíndros ,potência e peso.</p>
<pre class="r"><code>check_model(modelo)</code></pre>
<p><img src="{{< blogdown/postref >}}index_files/figure-html/unnamed-chunk-4-1.png" width="672" />
Checando o modelo temos uma baixa colinearidade, ou seja, não temos variáveis explicando a mesma coisa, cada uma contribui de forma diferentes para ocorrer a regressão. Podemos dizer que a variância é homogênia,porém a temos que quanto mais consome combustivel os carros tem uma diferença possivelmente significativa. Temos alguns pontos influêntes ,porém não significativos.</p>
<p>O final temos o relátorio.</p>
<pre class="r"><code>cat(report(modelo))</code></pre>
<pre><code>## We fitted a linear model (estimated using OLS) to predict mpg with cyl (formula: mpg ~ cyl + hp + wt). The model explains a statistically significant and substantial proportion of variance (R2 = 0.84, F(3, 28) = 50.17, p &lt; .001, adj. R2 = 0.83). The model&#39;s intercept, corresponding to cyl = 0, is at 38.75 (95% CI [35.09, 42.41], t(28) = 21.69, p &lt; .001). Within this model:
## 
##   - The effect of cyl is statistically non-significant and negative (beta = -0.94, 95% CI [-2.07, 0.19], t(28) = -1.71, p = 0.098; Std. beta = -0.28, 95% CI [-0.61, 0.06])
##   - The effect of hp is statistically non-significant and negative (beta = -0.02, 95% CI [-0.04, 6.29e-03], t(28) = -1.52, p = 0.140; Std. beta = -0.21, 95% CI [-0.48, 0.07])
##   - The effect of wt is statistically significant and negative (beta = -3.17, 95% CI [-4.68, -1.65], t(28) = -4.28, p &lt; .001; Std. beta = -0.51, 95% CI [-0.76, -0.27])
## 
## Standardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald t-distribution approximation. We fitted a linear model (estimated using OLS) to predict mpg with hp (formula: mpg ~ cyl + hp + wt). The model explains a statistically significant and substantial proportion of variance (R2 = 0.84, F(3, 28) = 50.17, p &lt; .001, adj. R2 = 0.83). The model&#39;s intercept, corresponding to hp = 0, is at 38.75 (95% CI [35.09, 42.41], t(28) = 21.69, p &lt; .001). Within this model:
## 
##   - The effect of cyl is statistically non-significant and negative (beta = -0.94, 95% CI [-2.07, 0.19], t(28) = -1.71, p = 0.098; Std. beta = -0.28, 95% CI [-0.61, 0.06])
##   - The effect of hp is statistically non-significant and negative (beta = -0.02, 95% CI [-0.04, 6.29e-03], t(28) = -1.52, p = 0.140; Std. beta = -0.21, 95% CI [-0.48, 0.07])
##   - The effect of wt is statistically significant and negative (beta = -3.17, 95% CI [-4.68, -1.65], t(28) = -4.28, p &lt; .001; Std. beta = -0.51, 95% CI [-0.76, -0.27])
## 
## Standardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald t-distribution approximation. We fitted a linear model (estimated using OLS) to predict mpg with wt (formula: mpg ~ cyl + hp + wt). The model explains a statistically significant and substantial proportion of variance (R2 = 0.84, F(3, 28) = 50.17, p &lt; .001, adj. R2 = 0.83). The model&#39;s intercept, corresponding to wt = 0, is at 38.75 (95% CI [35.09, 42.41], t(28) = 21.69, p &lt; .001). Within this model:
## 
##   - The effect of cyl is statistically non-significant and negative (beta = -0.94, 95% CI [-2.07, 0.19], t(28) = -1.71, p = 0.098; Std. beta = -0.28, 95% CI [-0.61, 0.06])
##   - The effect of hp is statistically non-significant and negative (beta = -0.02, 95% CI [-0.04, 6.29e-03], t(28) = -1.52, p = 0.140; Std. beta = -0.21, 95% CI [-0.48, 0.07])
##   - The effect of wt is statistically significant and negative (beta = -3.17, 95% CI [-4.68, -1.65], t(28) = -4.28, p &lt; .001; Std. beta = -0.51, 95% CI [-0.76, -0.27])
## 
## Standardized parameters were obtained by fitting the model on a standardized version of the dataset. 95% Confidence Intervals (CIs) and p-values were computed using a Wald t-distribution approximation.</code></pre>
</div>
</div>
